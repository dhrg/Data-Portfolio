{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why is gradient descent so bad at optimizing polynomial regression?# \n",
    "\n",
    "Question from Stackexchange\n",
    "\n",
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def costfunction(theta,X,y):\n",
    "    m = np.size(y)\n",
    "    theta = theta.reshape(-1,1)\n",
    "    \n",
    "    #Cost function in vectorized form\n",
    "    h = X @ theta\n",
    "    J = float((1./(2*m)) * (h - y).T @ (h - y));    \n",
    "    return J;\n",
    "\n",
    "def gradient_descent(theta,X,y,alpha = 0.0005,num_iters=1000):\n",
    "    m = np.size(y)\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        #Grad function in vectorized form\n",
    "        h = X @ theta\n",
    "        theta = theta - alpha * (1/m)* (X.T @ (h-y))\n",
    "        \n",
    "    return theta\n",
    "\n",
    "def grad(theta,X,y):\n",
    "    #Initializations\n",
    "    theta = theta[:,np.newaxis]\n",
    "    m = len(y)\n",
    "    grad = np.zeros(theta.shape)\n",
    "    \n",
    "    #Computations\n",
    "    h = X @ theta\n",
    "    \n",
    "    grad = (1./m)*(X.T @ ( h - y))\n",
    "    \n",
    "    return (grad.flatten())\n",
    "\n",
    "\n",
    "def polynomial_features(data, deg):\n",
    "    data_copy=data.copy()\n",
    "    \n",
    "    for i in range(1,deg):\n",
    "        data_copy['X'+str(i+1)]=data_copy['X'+str(i)]*data_copy['X1']\n",
    "\n",
    "    return data_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create data from sin function with uniform noise\n",
    "x = np.linspace(0,1,40)\n",
    "noise = 1*np.random.uniform(  size = 40)\n",
    "y = np.sin(x * 1.5 * np.pi ) \n",
    "y_noise = (y + noise).reshape(-1,1)\n",
    "X = np.vstack((np.ones(len(x)),x)).T\n",
    "\n",
    "degree = 15\n",
    "X_d = polynomial_features(pd.DataFrame({'X0':1,'X1': x}),degree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Closed form solution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.68976477e-01],\n",
       "       [ 4.14046200e+01],\n",
       "       [-9.03017908e+02],\n",
       "       [ 9.58065441e+03],\n",
       "       [-4.49088574e+04],\n",
       "       [ 5.96962228e+04],\n",
       "       [ 3.18227898e+05],\n",
       "       [-1.72978262e+06],\n",
       "       [ 3.86409797e+06],\n",
       "       [-4.70824016e+06],\n",
       "       [ 3.23743378e+06],\n",
       "       [-1.74472645e+06],\n",
       "       [ 2.06049877e+06],\n",
       "       [-2.41570547e+06],\n",
       "       [ 1.40990123e+06],\n",
       "       [-3.15211551e+05]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def closed_form_solution(X,y):\n",
    "    return np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "\n",
    "closed_form_solution(X_d.values,y_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy only fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.0468006 ],\n",
       "       [ 0.84807577],\n",
       "       [-0.62152239],\n",
       "       [-0.91258239],\n",
       "       [-0.80166835],\n",
       "       [-0.59678275],\n",
       "       [-0.3974059 ],\n",
       "       [-0.23015392],\n",
       "       [-0.09770137],\n",
       "       [ 0.00433034],\n",
       "       [ 0.08165229],\n",
       "       [ 0.13949769],\n",
       "       [ 0.18217817],\n",
       "       [ 0.21309703],\n",
       "       [ 0.23489246],\n",
       "       [ 0.24959621]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_result_1 = gradient_descent(np.zeros((len(X_d.T),1)).reshape(-1,1), X_d,y_noise,alpha = .1,num_iters=1000)\n",
    "theta_result_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sciy optimize fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.3653751 ,   5.01714559,   2.42495055, -19.64125507,\n",
       "        -3.33104422,   9.07415879,  10.59592578,   6.11927452,\n",
       "         0.50261061,  -3.6346289 ,  -5.45126495,  -5.11773491,\n",
       "        -3.26010397,  -0.63362555,   2.04526255,   4.17234749])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.optimize as opt\n",
    "\n",
    "theta_init = np.ones((len(X_d.T),1)).reshape(-1,1)\n",
    "model_t = opt.minimize(fun = costfunction, x0 = theta_init , args = (X_d, y_noise), \n",
    "                             method = 'BFGS', jac = grad, options={'maxiter':1000})\n",
    "model_t.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn fit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.01597858e-01,  6.83509165e+01, -2.91401167e+03,\n",
       "         5.22721768e+04, -4.88790193e+05,  2.56258615e+06,\n",
       "        -6.73068632e+06, -9.34747716e+05,  7.34271140e+07,\n",
       "        -2.83379636e+08,  6.03268254e+08, -8.23368800e+08,\n",
       "         7.38684424e+08, -4.22986907e+08,  1.40557246e+08,\n",
       "        -2.06594837e+07]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "model_d = linear_model.LinearRegression(fit_intercept=False)\n",
    "model_d.fit(X_d,y_noise)\n",
    "model_d.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statsmodel fit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.903\n",
      "Model:                            OLS   Adj. R-squared:                  0.842\n",
      "Method:                 Least Squares   F-statistic:                     14.82\n",
      "Date:                Wed, 06 Jun 2018   Prob (F-statistic):           1.23e-08\n",
      "Time:                        21:11:37   Log-Likelihood:                 2.6712\n",
      "No. Observations:                  40   AIC:                             26.66\n",
      "Df Residuals:                      24   BIC:                             53.68\n",
      "Df Model:                          15                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "X0             0.3016      0.292      1.033      0.312      -0.301       0.904\n",
      "X1            68.3509     72.764      0.939      0.357     -81.827     218.529\n",
      "X2         -2914.0117   4464.294     -0.653      0.520   -1.21e+04    6299.839\n",
      "X3          5.227e+04   1.13e+05      0.461      0.649   -1.82e+05    2.86e+05\n",
      "X4         -4.888e+05   1.57e+06     -0.312      0.758   -3.72e+06    2.74e+06\n",
      "X5          2.563e+06   1.34e+07      0.191      0.850   -2.51e+07    3.02e+07\n",
      "X6         -6.731e+06   7.65e+07     -0.088      0.931   -1.65e+08    1.51e+08\n",
      "X7         -9.347e+05   3.04e+08     -0.003      0.998   -6.28e+08    6.26e+08\n",
      "X8          7.343e+07   8.61e+08      0.085      0.933    -1.7e+09    1.85e+09\n",
      "X9         -2.834e+08   1.77e+09     -0.160      0.874   -3.93e+09    3.36e+09\n",
      "X10         6.033e+08   2.63e+09      0.229      0.821   -4.83e+09    6.03e+09\n",
      "X11        -8.234e+08   2.81e+09     -0.293      0.772   -6.62e+09    4.98e+09\n",
      "X12         7.387e+08    2.1e+09      0.352      0.728   -3.59e+09    5.07e+09\n",
      "X13         -4.23e+08   1.04e+09     -0.407      0.688   -2.57e+09    1.72e+09\n",
      "X14         1.406e+08   3.07e+08      0.457      0.652   -4.94e+08    7.75e+08\n",
      "X15        -2.066e+07    4.1e+07     -0.504      0.619   -1.05e+08    6.39e+07\n",
      "==============================================================================\n",
      "Omnibus:                        2.255   Durbin-Watson:                   2.967\n",
      "Prob(Omnibus):                  0.324   Jarque-Bera (JB):                1.559\n",
      "Skew:                          -0.261   Prob(JB):                        0.459\n",
      "Kurtosis:                       2.186   Cond. No.                     1.49e+11\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 3.51e-21. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "model_sm = sm.OLS(y_noise, X_d)\n",
    "res = model_sm.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
